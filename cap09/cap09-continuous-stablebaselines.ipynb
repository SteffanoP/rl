{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Ações Contínuas com Stable Baselines3\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pablo-sampaio/rl_facil/blob/main/cap09/cap09-continuous-stablebaselines.ipynb) \n",
        "\n",
        "Vamos usar os algoritmo **DDPG**, **TD3** e **SAC** neste Google Colab.\n",
        "\n",
        "Referências:\n",
        "- Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "- Documentação: https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "## 1 - Configurações necessárias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thRA4CT9kH4G"
      },
      "source": [
        "### 1.1 Instalação de pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gWskDE2c9WoN"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install gym[all]==00.25.1\n",
        "!pip install gym[atari,accept-rom-license]==00.25.1\n",
        "!pip install pyglet\n",
        "!pip install stable-baselines3[extra]\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir log_dir"
      ],
      "metadata": {
        "id": "WL9KXKZbWWH6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLlWktrRj9GZ"
      },
      "source": [
        "### 1.2 Para salvar vídeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "outputs": [],
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRNUfulOGaF"
      },
      "source": [
        "A gravação é feita com o wrapper [VecVideoRecorder](https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html#vecvideorecorder)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Trag9dQpOIhx"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(env_id, model, video_length=500, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param env_id: (str)\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
        "  # Start the video at step=0 and record the given number of steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "### 1.3 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BIedd7Pz9sOs",
        "outputId": "a8bd189f-1476-49c8-98f8-3c98e6ae90c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "import stable_baselines3\n",
        "stable_baselines3.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wgAXxClR0BfH"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "from stable_baselines3 import DDPG, TD3, SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Ativa Tensorboard"
      ],
      "metadata": {
        "id": "jc5wz5fxULad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acompanhe, principalmente, o indicador `ep_rew_mean` que é a **recompensa média por episódio** (= **retorno médio**).\n",
        "\n",
        "Também vale a pena comparar diferentes algoritmos quanto ao \"tempo de relógio\". Escolha `RELATIVE` para o eixo horizontal."
      ],
      "metadata": {
        "id": "OZT5kG3iGnpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir log_dir"
      ],
      "metadata": {
        "id": "Bv9BPUyOUOZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## 3 - Cria e Treina um Agente"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Algumas opções de ambientes com ações contínuas:\n",
        "# 'Pendulum-v1', 'LunarLanderContinuous-v2', 'MountainCarContinuous-v0', 'BipedalWalker-v3'\n",
        "ENVIRONMENT_ID = \"Pendulum-v1\"  \n",
        "\n",
        "env = gym.make(ENVIRONMENT_ID)\n",
        "\n",
        "# The noise objects for DDPG and TD3\n",
        "n_actions = env.action_space.shape[-1]\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "policy_kwargs = None"
      ],
      "metadata": {
        "id": "Ti41sducUWkS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descomente o código abaixo, se quiser definir o números de nós por camada intermediária das redes que representam política **pi** (chave `pi` do dicionário) e do crítico **Q** (chave `qf`). \n",
        "\n",
        "Mais informações: https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html."
      ],
      "metadata": {
        "id": "zoJ6vUp2Et6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pUWGZp3i9wyf"
      },
      "outputs": [],
      "source": [
        "# Ator com duas camadas: de 128 e 256 unidades / Crítico com duas camadas de 256 unidades cada\n",
        "#policy_kwargs = dict( net_arch=dict(pi=[128, 256], qf=[256, 256]) )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escolha um dos algoritmos abaixo descomentando a linha correspondente. Mais informações:\n",
        "- **DDPG**: https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html\n",
        "- **TD3**: https://stable-baselines3.readthedocs.io/en/master/modules/td3.html\n",
        "- **SAC**: https://stable-baselines3.readthedocs.io/en/master/modules/sac.html"
      ],
      "metadata": {
        "id": "60lXPd83EtZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria o agente\n",
        "#model = DDPG(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, action_noise=action_noise, tensorboard_log=\"log_dir\", verbose=1)\n",
        "#model = TD3(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, action_noise=action_noise, tensorboard_log=\"log_dir\", verbose=1)\n",
        "model = SAC(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, tensorboard_log=\"log_dir\", verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MlrFzxdCqoE",
        "outputId": "5a1f3a7b-c383-47db-c825-88b04e496a9d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avalia o agente antes de treinado\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"Retorno médio: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "wIpcMv3Fcjk_",
        "outputId": "63614362-0eb7-403f-d9cb-56c0a4cecc33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retorno médio: -92.31 +/- 0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica o treinamento\n",
        "model.learn(total_timesteps=20000, log_interval=10)"
      ],
      "metadata": {
        "id": "cwOm3u2ZT-Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Exibe e Avalia o agente"
      ],
      "metadata": {
        "id": "lddRTK2LdWvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "record_video(ENVIRONMENT_ID, model, video_length=1000, prefix='alg-treinado')\n",
        "show_videos('videos', prefix='alg-treinado')"
      ],
      "metadata": {
        "id": "MGjHsreQUBtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5SoCtCVAiX0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515f9340-4954-4537-9a19-40b05eb4d582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retorno médio: -81.67 +/- 14.28\n"
          ]
        }
      ],
      "source": [
        "# Avalia o agente treinado\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"Retorno médio: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pLlWktrRj9GZ"
      ],
      "name": "cap09-continuous-stablebaselines.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('rlx')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "27dbc9ce4cc602e4f15257b7b0018d8dff5b9ce9a7d73bc4399cb5afb1e02c4a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}