{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Ações Contínuas com Stable Baselines3\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pablo-sampaio/rl_facil/blob/main/cap09/cap09-3-DDPG-stablebaselines.ipynb)\n",
        "\n",
        "Vamos usar os algoritmo **DDPG**, **TD3** e **SAC** neste Google Colab.\n",
        "\n",
        "Referências:\n",
        "- Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "- Documentação: https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "## 1 - Configurações necessárias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thRA4CT9kH4G"
      },
      "source": [
        "### 1.1 Instalação de pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWskDE2c9WoN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from IPython.display import clear_output\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "    !pip install \"stable-baselines3[extra]==2.0.0\"\n",
        "    #clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL9KXKZbWWH6"
      },
      "outputs": [],
      "source": [
        "!mkdir log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLlWktrRj9GZ"
      },
      "source": [
        "### 1.2 Para salvar vídeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    # Set up fake display; otherwise rendering will fail\n",
        "    import os\n",
        "    os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRNUfulOGaF"
      },
      "source": [
        "A gravação é feita com o wrapper [VecVideoRecorder](https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html#vecvideorecorder)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Trag9dQpOIhx"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(env_id, model, video_length=500, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param env_id: (str)\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
        "  # Start the video at step=0 and record the given number of steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "### 1.3 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "import tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "import stable_baselines3\n",
        "stable_baselines3.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgAXxClR0BfH"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import DDPG, TD3, SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc5wz5fxULad"
      },
      "source": [
        "## 2 - Ativa Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZT5kG3iGnpp"
      },
      "source": [
        "Acompanhe, principalmente, o indicador `ep_rew_mean`, que é a **recompensa média por episódio** (= **retorno médio**).\n",
        "\n",
        "Também vale a pena comparar diferentes algoritmos quanto ao \"tempo de relógio\": escolha `RELATIVE` para o eixo horizontal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv9BPUyOUOZi"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## 3 - Cria e Treina um Agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti41sducUWkS"
      },
      "outputs": [],
      "source": [
        "# Algumas opções de ambientes com ações contínuas:\n",
        "# 'Pendulum-v1', 'LunarLanderContinuous-v2', 'MountainCarContinuous-v0', 'BipedalWalker-v3'\n",
        "ENVIRONMENT_ID = \"Pendulum-v1\"\n",
        "\n",
        "env = gym.make(ENVIRONMENT_ID)\n",
        "\n",
        "# The noise objects for DDPG and TD3\n",
        "n_actions = env.action_space.shape[-1]\n",
        "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
        "policy_kwargs = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoJ6vUp2Et6u"
      },
      "source": [
        "Descomente o código abaixo, se quiser definir o números de nós por camada intermediária das redes que representam política **pi** (chave `pi` do dicionário) e do crítico **Q** (chave `qf`).\n",
        "\n",
        "Mais informações: https://stable-baselines.readthedocs.io/en/master/guide/custom_policy.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUWGZp3i9wyf"
      },
      "outputs": [],
      "source": [
        "# Ator com duas camadas: de 128 e 256 unidades / Crítico com duas camadas de 256 unidades cada\n",
        "#policy_kwargs = dict( net_arch=dict(pi=[128, 256], qf=[256, 256]) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60lXPd83EtZ7"
      },
      "source": [
        "Escolha um dos algoritmos abaixo descomentando a linha correspondente. Mais informações:\n",
        "- **DDPG**: https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html\n",
        "- **TD3**: https://stable-baselines3.readthedocs.io/en/master/modules/td3.html\n",
        "- **SAC**: https://stable-baselines3.readthedocs.io/en/master/modules/sac.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MlrFzxdCqoE"
      },
      "outputs": [],
      "source": [
        "# Cria o agente\n",
        "model = DDPG(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, action_noise=action_noise, tensorboard_log=\"log_dir\", verbose=1)\n",
        "#model = TD3(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, action_noise=action_noise, tensorboard_log=\"log_dir\", verbose=1)\n",
        "#model = SAC(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, tensorboard_log=\"log_dir\", verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIpcMv3Fcjk_"
      },
      "outputs": [],
      "source": [
        "# Avalia o agente antes de treinado\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"Retorno médio: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwOm3u2ZT-Tb"
      },
      "outputs": [],
      "source": [
        "# Aplica o treinamento\n",
        "model.learn(total_timesteps=20_000, log_interval=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lddRTK2LdWvI"
      },
      "source": [
        "## 4 - Exibe e Avalia o agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGjHsreQUBtS"
      },
      "outputs": [],
      "source": [
        "record_video(ENVIRONMENT_ID, model, video_length=1000, prefix='alg-treinado')\n",
        "show_videos('videos', prefix='alg-treinado')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SoCtCVAiX0O"
      },
      "outputs": [],
      "source": [
        "# Avalia o agente treinado\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
        "print(f\"Retorno médio: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2gcBxhyFf40"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pLlWktrRj9GZ"
      ],
      "name": "cap09-3-DDPG-stablebaselines.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('rlx')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "27dbc9ce4cc602e4f15257b7b0018d8dff5b9ce9a7d73bc4399cb5afb1e02c4a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
