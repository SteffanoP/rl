{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeJ3wCaKe2Wl"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pablo-sampaio/rl_facil/blob/main/cap09/cap09-main.ipynb)\n",
        "\n",
        "# Capítulo 9 - Introdução ao Policy Gradient - Reinforce\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAHITU7VhsM7"
      },
      "source": [
        "## Configurações Iniciais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS23BU8R1vq-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from IPython.display import clear_output\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install gymnasium[box2d]\n",
        "\n",
        "    # para salvar videos\n",
        "    !apt-get install -y ffmpeg xvfb x11-utils\n",
        "\n",
        "    !git clone https://github.com/pablo-sampaio/rl_facil\n",
        "    sys.path.append(\"/content/rl_facil\")\n",
        "\n",
        "    clear_output()\n",
        "else:\n",
        "    from os import path\n",
        "    sys.path.append( path.dirname( path.dirname( path.abspath(\"__main__\") ) ) )\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnrVvE_i010L"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    import os\n",
        "    os.system(\"Xvfb :1 -screen 0 1400x900x24 &\")\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Gzf7VhkiHxQ"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "from util.experiments import repeated_exec\n",
        "from util.plot import plot_result, plot_multiple_results\n",
        "from util.notebook import display_videos_from_path\n",
        "\n",
        "from cap08.models_torch_pg import PolicyModelPG, test_policy\n",
        "from cap08.reinforce import run_reinforce\n",
        "from cap08.reinforce_advantage import run_reinforce_with_adv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztvJdbKVh20Y"
      },
      "source": [
        "## 1 - Rodando o Reinforce (Vanilla Policy Gradient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OACm0r-iuh2"
      },
      "outputs": [],
      "source": [
        "ENV_NAME, rmax = \"CartPole-v1\", 500\n",
        "#ENV_NAME, rmax = \"Acrobot-v1\", 0\n",
        "#ENV_NAME, rmax = \"LunarLander-v2\", 150\n",
        "#ENV_NAME, rmax = \"MountainCar-v0\", -20\n",
        "\n",
        "EPISODES = 1000\n",
        "GAMMA    = 0.99\n",
        "\n",
        "env = gym.make(ENV_NAME)\n",
        "inputs = env.observation_space.shape[0]\n",
        "outputs = env.action_space.n\n",
        "policy1 = PolicyModelPG(inputs, [128, 512], outputs, lr=0.0005)\n",
        "\n",
        "returns1, policy1 = run_reinforce(env, EPISODES, 0.95, initial_policy=policy1)\n",
        "clear_output()\n",
        "\n",
        "print(\"Últimos episódios do treinamento: media =\", np.mean(returns1[-20:]), \", desvio padrao =\", np.std(returns1[-20:]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE8aezOFJIBv"
      },
      "outputs": [],
      "source": [
        "# Exibe um gráfico episódios x retornos (não descontados)\n",
        "plot_result(returns1, rmax, window=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K56oy-IY010S"
      },
      "outputs": [],
      "source": [
        "# Roda alguns episódigos com o modelo e salva os vídeos em arquivos\n",
        "# TODO: \n",
        "#  - rever, deixar parecido com a forma da função usada nos notebooks do stable-baselines, gravando um só vídeo de tamanho fixo (com possivelmente vários episódios)\n",
        "#  - permitir renderizar OU gravar -- passar apenas a string do ambiente e chamar o make appropriado\n",
        "\n",
        "env1 = gym.make(ENV_NAME, render_mode=\"rgb_array\")\n",
        "video_env = gym.wrappers.RecordVideo(env1, \"./vid-reinf\", episode_trigger=(lambda ep : True), video_length=1_500)\n",
        "test_policy(video_env, policy1, False, 3, render=False)\n",
        "video_env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOVtCyYl010T"
      },
      "outputs": [],
      "source": [
        "display_videos_from_path('./vid-reinf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKgs_SqvJIBw"
      },
      "source": [
        "## 2 - Rodando o Reinforce com Advantage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSSg57UHJIBw"
      },
      "outputs": [],
      "source": [
        "ENV_NAME, rmax = \"CartPole-v1\", 500\n",
        "#ENV_NAME, rmax = \"Acrobot-v1\", 0\n",
        "#ENV_NAME, rmax = \"LunarLander-v2\", 150\n",
        "#ENV_NAME, rmax = \"MountainCar-v0\", -20\n",
        "\n",
        "EPISODES = 1000\n",
        "GAMMA    = 0.99\n",
        "\n",
        "env = gym.make(ENV_NAME)\n",
        "inputs = env.observation_space.shape[0]\n",
        "outputs = env.action_space.n\n",
        "policy2 = PolicyModelPG(inputs, [128, 512], outputs, lr=0.001)\n",
        "\n",
        "returns2, policy2 = run_reinforce_with_adv(env, EPISODES, GAMMA, initial_policy=policy2)\n",
        "clear_output()\n",
        "\n",
        "print(\"Últimos episódios do treinamento: media =\", np.mean(returns2[-20:]), \", desvio padrao =\", np.std(returns2[-20:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G1ltM3TJIBx"
      },
      "outputs": [],
      "source": [
        "# Exibe um gráfico episódios x retornos (não descontados)\n",
        "plot_result(returns2, rmax, window=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qhl5Wr47010Y"
      },
      "outputs": [],
      "source": [
        "# Roda alguns episódigos com o modelo e salva os vídeos em arquivos\n",
        "env2 = gym.make(ENV_NAME)\n",
        "env1 = gym.make(ENV_NAME, render_mode=\"rgb_array\")\n",
        "video_env = gym.wrappers.RecordVideo(env1, \"./vid-reinf-adv\", episode_trigger=(lambda ep : True), video_length=1_600)\n",
        "test_policy(video_env, policy2, False, 3, render=False)\n",
        "video_env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTIjbY6CJIBx"
      },
      "outputs": [],
      "source": [
        "display_videos_from_path('./vid-reinf-adv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8roKzCgsuCl"
      },
      "source": [
        "## 3 - Experimentos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwhQnziOGf4Q"
      },
      "source": [
        "### 3.1 Comparações Básicas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id3nU0eD010a"
      },
      "outputs": [],
      "source": [
        "AUTO_LOAD = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aU8DNpphvcRa"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "NUM_EPISODES = 2000\n",
        "\n",
        "results3 = []\n",
        "\n",
        "results3.append( repeated_exec(3, f\"Reinforce\", run_reinforce, env, NUM_EPISODES, gamma=0.95, auto_load=AUTO_LOAD) )\n",
        "clear_output()\n",
        "\n",
        "results3.append( repeated_exec(3, f\"Reinforce-Adv\", run_reinforce_with_adv, env, NUM_EPISODES, gamma=0.95, auto_load=AUTO_LOAD) )\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF589eYV010d"
      },
      "outputs": [],
      "source": [
        "#plot_multiple_results(results3, cumulative=False, x_log_scale=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnIDdB_y010d"
      },
      "outputs": [],
      "source": [
        "plot_multiple_results(results3, cumulative=False, plot_stddev=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5T13ZeqGf4Q"
      },
      "source": [
        "### 3.2 Variando Parâmetros da Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0toL7Es010e"
      },
      "source": [
        "Vamos mostrar comparações variando apenas a quantidade de neurônios da (única) camada intermediária.\n",
        "\n",
        "Você pode também variar todos os outros parâmetros da rede neural: quantidade de camadas e taxa de aprendizagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI9mq0GVJIBz"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "NUM_EPISODES = 1000\n",
        "\n",
        "print(\"Observation Space - \", env.observation_space.shape)\n",
        "print(\"Observation Space - shape\", env.observation_space.shape)\n",
        "print(\"Action Space - \", env.action_space)\n",
        "print(\"Action Space - number of actions - \", env.action_space.n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7zUcdS5Gf4R"
      },
      "outputs": [],
      "source": [
        "results4 = []\n",
        "\n",
        "for hidden_layer_size in [16, 128]:\n",
        "    policy_model = PolicyModelPG(env.observation_space.shape[0], [hidden_layer_size], env.action_space.n, lr=0.01)\n",
        "    results4.append( repeated_exec(3, f\"Reinforce (hnodes={hidden_layer_size})\", run_reinforce, env, NUM_EPISODES, 0.99, policy_model, auto_load=AUTO_LOAD) )\n",
        "    clear_output()\n",
        "    results4.append( repeated_exec(3, f\"Reinforce-Adv (hnodes={hidden_layer_size})\", run_reinforce_with_adv, env, NUM_EPISODES, 0.99, policy_model, auto_load=AUTO_LOAD) )\n",
        "    clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIn4a1E7010f"
      },
      "outputs": [],
      "source": [
        "#results4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2DhMMlS010f"
      },
      "outputs": [],
      "source": [
        "plot_multiple_results(results4, cumulative=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCrN2hXL010g"
      },
      "outputs": [],
      "source": [
        "#plot_multiple_results(results4, cumulative=False, plot_stddev=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cap08-main-1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('rlx')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "27dbc9ce4cc602e4f15257b7b0018d8dff5b9ce9a7d73bc4399cb5afb1e02c4a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
