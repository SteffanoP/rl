{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeJ3wCaKe2Wl"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pablo-sampaio/rl_facil/blob/main/cap06/cap06-main.ipynb)\n",
    "\n",
    "# Capítulo 6 - SARSA de _n_ passos / Tratando Estados Contínuos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAHITU7VhsM7"
   },
   "source": [
    "## Configurações Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NS23BU8R1vq-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # for saving videos\n",
    "    !apt-get install ffmpeg\n",
    "\n",
    "    !pip install gymnasium moviepy\n",
    "    !pip install optuna\n",
    "\n",
    "    # clone repository\n",
    "    !git clone https://github.com/pablo-sampaio/rl_facil\n",
    "    sys.path.append(\"/content/rl_facil\")\n",
    "\n",
    "else:\n",
    "    from os import path\n",
    "    sys.path.append( path.dirname( path.dirname( path.abspath(\"__main__\") ) ) )\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0Gzf7VhkiHxQ"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from cap06.nstep_sarsa import run_nstep_sarsa\n",
    "\n",
    "from envs import RacetrackEnv\n",
    "from envs.wrappers import ObservationDiscretizerWrapper\n",
    "\n",
    "from util.experiments import repeated_exec\n",
    "from util.plot import plot_result, plot_multiple_results\n",
    "from util.notebook import display_videos_from_path\n",
    "from util.qtable_helper import evaluate_qtable, record_video_qtable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-xEwtye5J_r"
   },
   "source": [
    "## 1 - SARSA de n Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oypatF0t5J_t"
   },
   "source": [
    "É uma extensão do SARSA que usa uma sequência de de *n* passos (ou seja, com *n* ações realizadas no ambiente) como entrada para cada atualização da estimativa do $Q(s,a)$.\n",
    "\n",
    "Com **$n=1$**, ele estima $Q(s,a)$ igual ao *SARSA*:\n",
    "- usa esta experiência: $s, a, r_1, s_1, a_1$\n",
    "- calcula a nova estimativa de $Q(s,a)$ assim (para estados não-terminais):\n",
    "$$Q_{target} = r_1 + \\gamma . Q(s_1,a_1)$$\n",
    "- note que apenas 1 ação foi realizada ($a$) e apenas 1 recompensa foi recebida ($r_1$)\n",
    "- observe que a última ação ($a_1$) foi escolhida, mas não foi realizada no ambiente\n",
    "\n",
    "Com **$n=2$**, para estimar $Q(s,a)$, ele:\n",
    "- usa esta experiência: $s, a, r_1, s_1, a_1, r_2, s_2, a_2$\n",
    "- calcula a nova estimativa de $Q(s,a)$ assim:\n",
    "$$Q_{target} = r_1 + \\gamma .r_2 + \\gamma^2 . Q(s_2,a_2)$$\n",
    "- esta é uma estimativa mais precisa, que usa os dados de *duas* recompensas reais\n",
    "\n",
    "Para **$n$ qualquer**:\n",
    "- experiência: $s, a, r_1, s_1, a_1, r_2, s_2, a_2, s_3, \\cdots, r_n, s_n, a_n$\n",
    "- nova estimativa:\n",
    "$$Q_{target} = r_1 + \\gamma .r_2 + \\gamma^2 . r_2 + \\cdots + \\gamma^n . Q(s_n,a_n)$$\n",
    "\n",
    "O $n$ será um parâmetro do algoritmo.\n",
    "\n",
    "O código é mais complexo do que dos algoritmos de 1 passo. Veja o arquivo `cap06/nstep_sarsa.py` para conhecer os detalhes.\n",
    "\n",
    "Abaixo, vamos importar e usar aquela implementação para fazer um experimento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4x5E-zx85J_u"
   },
   "outputs": [],
   "source": [
    "# para ambientes gymnasium\n",
    "#ENV_NAME, r_max = \"Taxi-v3\", 10\n",
    "#ENV_NAME, r_max = \"CliffWalking-v0\", 0\n",
    "#ENV_NAME, r_max = \"FrozenLake-v1\", 0\n",
    "ENV_NAME, r_max = \"RaceTrack-v0\", 0\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "\n",
    "# para ambientes instanciados diretamente\n",
    "# atenção: vale a pena aplicar um TimeLimit\n",
    "#env = RacetrackEnv()\n",
    "#r_max = 0\n",
    "\n",
    "EPISODES = 5_000\n",
    "LR = 0.1\n",
    "GAMMA = 0.95\n",
    "EPSILON = 0.1\n",
    "NSTEPS = 5\n",
    "\n",
    "# Roda o algoritmo \"n-step SARSA\"\n",
    "rewards1, qtable1 = run_nstep_sarsa(env, EPISODES, NSTEPS, LR, GAMMA, EPSILON, verbose=True)\n",
    "print(\"Últimos resultados: media =\", np.mean(rewards1[-20:]), \", desvio padrao =\", np.std(rewards1[-20:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jfj6LvPI5J_u"
   },
   "outputs": [],
   "source": [
    "# Mostra um gráfico de episódios x retornos não descontados\n",
    "plot_result(rewards1, r_max, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wK4dvRUR5J_v"
   },
   "outputs": [],
   "source": [
    "evaluate_qtable(env, qtable1, 10, epsilon=0.1, verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atenção: precisa passar a ID do ambiente no gymnasium ou instanciar diretamente um novo ambiente com o render_mode \"rgb_array\"\n",
    "record_video_qtable(ENV_NAME, qtable1, episodes=3, folder='videos/', prefix='nstep-discrete')\n",
    "#record_video_qtable(RacetrackEnv(render_mode=\"rgb_array\"), qtable1, episodes=3, folder='videos/', prefix='nstep-discrete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos_from_path('./videos', prefix='nstep-discrete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, vamos rodar alguns experimentos variando a quantidade de passos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wkpV4ENC5J_v"
   },
   "outputs": [],
   "source": [
    "RUNS = 3\n",
    "results1 = []\n",
    "for nstep in [1, 2, 3]:\n",
    "    results1.append( repeated_exec(RUNS, f\"{nstep}-step SARSA (LR={LR})\", run_nstep_sarsa, env, EPISODES, nstep, LR) )\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1Ehr5Eh5J_v"
   },
   "outputs": [],
   "source": [
    "plot_multiple_results(results1, window=30, x_log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztvJdbKVh20Y"
   },
   "source": [
    "## 2 - Lidando com Estados Contínuos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos usar os mesmos algoritmos de antes, baseados em Q-Table, para lidar com ambientes de estados contínuos. \n",
    "\n",
    "Para isso, vamos usar um *wrapper* que discretiza os estados desses ambientes.\n",
    "\n",
    "Primeiramente, vamos analisar, abaixo, o espaço de estados de um ambiente contínuo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OACm0r-iuh2"
   },
   "outputs": [],
   "source": [
    "ENV_NAME = \"CartPole-v1\"\n",
    "r_max_plot = 200\n",
    "\n",
    "env2a = gym.make(ENV_NAME)\n",
    "\n",
    "# vamos ver como é um estado deste ambiente?\n",
    "print(\"Espaço de estados/observações: \", env2a.observation_space)\n",
    "print(\"  - formato: \", env2a.observation_space.shape)\n",
    "print(\"  - exemplo: \", env2a.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, nós encapsulamos o ambiente contínuo em um wrapper para discretizá-lo.\n",
    "\n",
    "Os parâmetros indicam quantos valores discretos foram usados para representar cada uma das dimensões do estado.\n",
    "\n",
    "Como resultado, o espaço de estados torna-se do tipo `Discrete`, o que indica que cada \"estado\" é representado como um único número inteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vplFS4jKuA4m"
   },
   "outputs": [],
   "source": [
    "# Encapsula o ambiente em nosso wrapper\n",
    "# atenção para o parâmetro BINS: deve ter um valor para cada componente do estado\n",
    "BINS = [5, 30, 30, 30]\n",
    "env2b = ObservationDiscretizerWrapper(env2a, BINS)\n",
    "\n",
    "env2b.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos rodar treinamentos com quaisquer dos algoritmos que temos visto. Vamos rodar o *SARSA de n passos*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Le0wNU9PrA8f"
   },
   "outputs": [],
   "source": [
    "EPISODES = 5_000\n",
    "LR = 0.2\n",
    "GAMMA = 0.95\n",
    "EPSILON = 0.1\n",
    "NSTEPS = 4\n",
    "\n",
    "rewards2, qtable2 = run_nstep_sarsa(env2b, EPISODES, NSTEPS, LR, GAMMA, EPSILON, verbose=True)\n",
    "\n",
    "print(\"Últimos resultados: media =\", np.mean(rewards2[-20:]), \", desvio padrao =\", np.std(rewards2[-20:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXlD7B-pshru"
   },
   "outputs": [],
   "source": [
    "# Gera um gráfico de episódios x retornos (não descontados)\n",
    "plot_result(rewards2, r_max_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Bz2Pp1Wsi_P"
   },
   "outputs": [],
   "source": [
    "# Faz alguns testes, usando a tabela de forma greedy\n",
    "evaluate_qtable(env2b, qtable2, 10, 0.0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva vídeo\n",
    "# Atenção: é recomendado criar nova instância do ambiente e do wrapper!\n",
    "env_test = gym.make(ENV_NAME, render_mode=\"rgb_array\")\n",
    "env_test = ObservationDiscretizerWrapper(env_test, BINS)\n",
    "record_video_qtable(env_test, qtable2, episodes=3, folder='videos/', prefix='nstep-cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_LkBPgb5iz2"
   },
   "outputs": [],
   "source": [
    "# Exibe o video\n",
    "display_videos_from_path('./videos', prefix='nstep-cartpole')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8roKzCgsuCl"
   },
   "source": [
    "## 3 - Otimizando Parâmetros\n",
    "\n",
    "Vamos usar a biblioteca *Optuna* para otimizar (hiper-)parâmetros dos algoritmos de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Ambiente Discreto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBsJRMCstj0N"
   },
   "source": [
    "Este é o caso mais simples, porque não precisamos aplicar nenhum wrapper.\n",
    "\n",
    "Primeiro, você precisa fazer uma função que receber um parâmetro do tipo `Trial` (definido no optuna) e retorna uma medida de desempenho.\n",
    "\n",
    "Dentro da função, você usa o objeto *trial* para pedir \"sugestões\" de valores para os hiper-parâmetros do seu algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "aU8DNpphvcRa"
   },
   "outputs": [],
   "source": [
    "def train_nstep_sarsa_racetrack(trial : optuna.Trial):\n",
    "    # chama os métodos do \"trial\" (tentativa) para sugerir valores para os parâmetros\n",
    "    eps    = trial.suggest_float('epsilon', 0.01, 0.2)\n",
    "    gamma  = trial.suggest_float('gamma', 0.90, 1.00)\n",
    "    lr     = trial.suggest_float('lr', 0.001, 1.0, log=True) # sugere na escala log (maior chance de escolher valor menor)\n",
    "    nsteps = trial.suggest_int('nsteps', 1, 16)\n",
    "    \n",
    "    # outra opção trial.suggest_categorical('param', ['value1', 'value2'])\n",
    "\n",
    "    print(f\"\\nTRIAL #{trial.number}: {trial.params}\")\n",
    "\n",
    "    # cria o ambiente Racetrack, mas insere-o em um wrapper para limitar o tamanho do episódio\n",
    "    env = gym.make(\"RaceTrack-v0\")\n",
    "\n",
    "    # roda o algoritmo e recebe os retornos não-descontados\n",
    "    (returns, _) = run_nstep_sarsa(env, 3000, nsteps, lr=lr, epsilon=eps, gamma=gamma, verbose=False)\n",
    "\n",
    "    # média dos retornos dos últimos 100 episódios\n",
    "    return sum(returns[-100:])/100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUpVCri3v7v9"
   },
   "source": [
    "Depois, você cria um \"study\" do Optuna e manda otimizar sua função, indicando quantas tentativas (trials) ele vai fazer -- ou seja, quantas vezes a sua função vai ser executada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTVBjiirtOUP"
   },
   "outputs": [],
   "source": [
    "study1 = optuna.create_study(direction='maximize',\n",
    "                        storage='sqlite:///optuna_cap06.db',\n",
    "                        study_name='nstep_sarsa_racetrack',\n",
    "                        load_if_exists=True)\n",
    "\n",
    "# maximiza o valor de retorno de train_exp_sarsa, rodando \"n_trials\" vezes\n",
    "# o parâmetro \"n_jobs\" indica a quantidade de CPUs a serem usadas (-1 para usar todas)\n",
    "study1.optimize(train_nstep_sarsa_racetrack, n_trials=20, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MELHORES PARÂMETROS:\")\n",
    "print(study1.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N6eLcX7yfqd"
   },
   "source": [
    "### 3.2 - Ambiente Contínuo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, nós aplicamos o wrapper, que tem novos parâmetros (quantidade de \"bins\" por valor do estado).\n",
    "\n",
    "O wrapper é considerado parte da solução e, por isso, os bins são também parâmetros a serem otimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "t7Jbppx7zr8u"
   },
   "outputs": [],
   "source": [
    "def train_nstep_sarsa_cartpole(trial : optuna.Trial):\n",
    "    # para os parâmetros do algoritmo\n",
    "    eps    = trial.suggest_float('epsilon', 0.01, 0.2)\n",
    "    #gamma  = trial.suggest_float('gamma', 0.90, 1.00) # comentei, para deixar menos parâmetros\n",
    "    lr     = trial.suggest_float('lr', 0.001, 1.0, log=True) # sugere na escala log (maior chance de escolher valor menor)\n",
    "    nsteps = trial.suggest_int('nsteps', 1, 16)\n",
    "\n",
    "    # para os parâmetros da discretização\n",
    "    bins1 = trial.suggest_int('bins1', 10, 100, step=10)\n",
    "    bins2 = trial.suggest_int('bins2', 10, 100, step=10)\n",
    "    bins3 = trial.suggest_int('bins3', 10, 100, step=10)\n",
    "    bins4 = trial.suggest_int('bins4', 10, 100, step=10)\n",
    "\n",
    "    all_bins = [bins1, bins2, bins3, bins4]\n",
    "\n",
    "    print(f\"\\nTRIAL #{trial.number}: {trial.params}\")\n",
    "\n",
    "    # cria o ambiente e o coloca no wrapper\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    env_wrapper = ObservationDiscretizerWrapper(env, all_bins)\n",
    "\n",
    "    # roda o algoritmo, recebendo os retornos não-descontados\n",
    "    (returns, _) = run_nstep_sarsa(env_wrapper, 4000, nsteps, lr=lr, epsilon=eps, gamma=1.0, verbose=False)\n",
    "\n",
    "    # média dos retornos dos últimos 100 episódios\n",
    "    return sum(returns[-100:])/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_6xX6d_0lht"
   },
   "outputs": [],
   "source": [
    "study2 = optuna.create_study(direction='maximize',\n",
    "                        storage='sqlite:///optuna_cap06.db',\n",
    "                        study_name='nstep_sarsa_cartpole',\n",
    "                        load_if_exists=True)\n",
    "\n",
    "# maximiza o valor de retorno de train_expsarsa_continuous, rodando \"n_trials\" vezes\n",
    "study2.optimize(train_nstep_sarsa_cartpole, n_trials=20, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MELHORES PARÂMETROS:\")\n",
    "print(study2.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Dicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguem algumas dicas para usar o optuna:\n",
    "\n",
    "1. É importante rodar muitos trials (por volta de 100), para resultados mais confiáveis.\n",
    "1. Dentro da função, você deve mandar treinar por uma quantidade intermediária de iterações (=episódios, nos algoritmos):\n",
    "   - Deve ser relativamente pequena, para não demorar muito tempo rodando.\n",
    "   - Deve ser alta o suficiente para dar tempo chegar em um resultado.\n",
    "1. Também ajuda a obter bons resultados logo se você reduzir a quantidade de valores possíveis para cada parâmetro a ser otimizado. \n",
    "   - Para `float`, tente restringir os valores a uma faixa de valores úteis. Exemplo: para o `gamma`, coloque como mínimo `0.5` ou outro valor maior.\n",
    "   - Para `int`, coloque algum passo (parâmetro `step`) maior que 1, se for adequado. Exemplo: fiz isso com os bins, no exemplo acima.\n",
    "1. Para parâmetros `float` que reconhecidamente são melhores com baixos valores, faça `'log=True'`, para explorar mais a região dos valores menores.\n",
    "   - Exemplo: fiz isso com as taxas de aprendizagem\n",
    "1. Uma forma mais confiável (porém mais lenta) de avaliar um algoritmo é, dentro da função a ser otimizada, fazer várias execuções da função de treinamento e retornar a média ou a mediana\n",
    "1. Quando você fizer *qualquer* alteração dentro da função a ser otimizada, reinicie o estudo de uma dessas formas:\n",
    "   - Apague o arquivo \".db\"\n",
    "   - Ou mude o nome do estudo (parâmetro `study_name`)\n",
    "1. Se você não alterar nada da função a ser otimizada, você pode rodar novamente o método `.optimize()` com o mesmo `study_name` com segurança. Neste caso, ele irá carregar os dados dos *trials* anteriores e irá rodar novos trials na quantidade indicada por `n_trials`.\n",
    "1. Veja a quantidade de processadores da sua máquina e ajuste adequadamente o `n_jobs`, ou defina-o como -1 para usar todos eles.\n",
    "   - Se usar mais de 1 processador, evite interromper de forma \"forçada\" a execução do método `optimize()`, pois interromper pode resultar em comportamentos estranhos (principalmente em notebooks Jupyter).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yF9fggfZzFVV"
   },
   "source": [
    "## 4 - Experimentos Completos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que você descobriu bons parâmetros, que tal rodar um treinamento mais longo com o seu algoritmo?\n",
    "\n",
    "Para cada ambiente, comparar os parâmetros default com os parâmetros otimizados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdGNkV7T5J_z"
   },
   "source": [
    "### Racetrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYSG9xiHxBKe"
   },
   "outputs": [],
   "source": [
    "#env_race = TimeLimit(RacetrackEnv(), 500)\n",
    "env_race = gym.make(\"RaceTrack-v0\")\n",
    "NUM_EPISODES = 12_000\n",
    "RUNS = 3\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append( repeated_exec(RUNS, f\"SARSA n-passos (default)\", run_nstep_sarsa, env_race, NUM_EPISODES) )\n",
    "#clear_output()\n",
    "\n",
    "results.append( repeated_exec(RUNS, f\"SARSA n-passos (otimizado)\", run_nstep_sarsa, env_race, NUM_EPISODES, **study1.best_params) )\n",
    "clear_output()\n",
    "\n",
    "plot_multiple_results(results, x_log_scale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCNKUKy15J_z"
   },
   "source": [
    "### CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtsW88Z75J_0"
   },
   "outputs": [],
   "source": [
    "env_cart = gym.make(\"CartPole-v1\")\n",
    "NUM_EPISODES = 12_000\n",
    "RUNS = 3\n",
    "\n",
    "results = []\n",
    "\n",
    "wrapped_env_cart = ObservationDiscretizerWrapper(env_cart, [30,30,30,30])\n",
    "results.append( repeated_exec(RUNS, f\"SARSA n-passos (default)\", run_nstep_sarsa, wrapped_env_cart, NUM_EPISODES, auto_load=True) )\n",
    "#clear_output()\n",
    "\n",
    "params = study2.best_params\n",
    "\n",
    "wrapped_env_cart = ObservationDiscretizerWrapper(env_cart, [ params['bins1'], params['bins2'], params['bins3'], params['bins4'] ] )\n",
    "results.append( repeated_exec(RUNS, f\"SARSA n-passos (otimizado)\", run_nstep_sarsa, wrapped_env_cart, NUM_EPISODES, epsilon=params['epsilon'], lr=params['lr'], nsteps=params['nsteps'], auto_load=True) )\n",
    "clear_output()\n",
    "\n",
    "plot_multiple_results(results, x_log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "cap06-main.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "rl23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
