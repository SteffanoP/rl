{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F7HLPQPeV94m"
      },
      "source": [
        "Você pode rodar este notebook localmente ou no Colab. Para abrir diretamente no Colab, basta clicar no botão abaixo.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pablo-sampaio/rl_facil/blob/main/cap02_novo/cap02-main.ipynb) \n",
        "\n",
        "# Capítulo 2 - Explorando os ambientes\n",
        "\n",
        "Para isso, vamos explorar os ambientes (simuladores de tarefas) oferecidos no pacote **`gymnasium`** (antigo `gym`), para praticar e pesquisar RL. \n",
        "\n",
        "O `gymnaisum` inclui diversos ambientes interessantes. E na internet, você encontra outros ambientes compatíveis com este pacote.\n",
        "\n",
        "Os ambientes mais simples funcionam como **MDPs** (*Markov Decision Processes*), que vimos (ou veremos) nas aulas."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MYKcHICW2HxW"
      },
      "source": [
        "## Configurações Iniciais\n",
        "\n",
        "Para instalar e importar pacotes e configurar algumas coisas..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import sys\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    # for saving videos\n",
        "    !apt-get install ffmpeg freeglut3-dev xvfb\n",
        "    \n",
        "    !pip install gymnasium\n",
        "\n",
        "    # clone repository\n",
        "    !git clone https://github.com/pablo-sampaio/rl_facil\n",
        "    sys.path.append(\"/content/rl_facil\")\n",
        "\n",
        "    clear_output()\n",
        "\n",
        "else:\n",
        "    from os import path\n",
        "    sys.path.append( path.dirname( path.dirname( path.abspath(\"__main__\") ) ) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9GfciGyvZA2"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    # Set up fake display; otherwise rendering will fail\n",
        "    import os\n",
        "    os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibr-xyFVvZ44"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import time\n",
        "\n",
        "from util.notebook import display_videos_from_path"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "659YAN1F2VMu"
      },
      "source": [
        "## 1 - Testando Alguns Ambientes\n",
        "\n",
        "Veja a lista de ambientes do gym e a descrição de cada ambiente neste link: https://www.gymlibrary.dev/."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-7RVzsGP4UEE"
      },
      "source": [
        "### 1.1 Exemplo Detalhado\n",
        "\n",
        "A biblioteca gym oferece vários ambientes, que costuma ser criados pela string de identificação. Abaixo, mostramos como rodar o ambiente \"CartPole-v1\". \n",
        "\n",
        "Mostramos como passar **ações** para o ambiente e como ler as **observações (ou estados)** e as **recompensas** vindas dele.\n",
        "\n",
        "Para entender todos esses valores, veja a documentação deste ambiente em: https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QM99FoU6eXU",
        "outputId": "f3f30907-306d-4ead-a977-3246fffa51ff"
      },
      "outputs": [],
      "source": [
        "# instancia o ambiente, usando o identificador do ambiente\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
        "\n",
        "# para guardar a soma das recompensas\n",
        "sum_rewards = 0.0\n",
        "\n",
        "# inicia um episodio no ambiente e recebe a observação inicial e o dicionário 'info'\n",
        "state, _ = env.reset()\n",
        "\n",
        "# indica se o episódio encerrou\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    # exibe visualmente o estado do ambiente (se estiver rodando localmente)\n",
        "    #env.render()\n",
        "\n",
        "    # escolhe uma ação aleatória, usando uma função do próprio ambiente\n",
        "    # neste ponto, você pode usar um algoritmo qualquer para escolher a ação\n",
        "    action = env.action_space.sample()\n",
        "\n",
        "    # aplica a ação no ambiente e recebe uma 5-tupla\n",
        "    #      obs  - a próxima observação\n",
        "    #      r    - a recompensa deste passo\n",
        "    #      terminated - indica se o episódio acabou naturalmente por chegar em um estado terminal\n",
        "    #      truncated  - indica se o episódio acabou de forma não natural (por chegar em um limite de tempo, digamos)\n",
        "    #      info - dicionário com informações extras (pode ser ignorado)\n",
        "    (state, r, terminated, truncated, _) = env.step(action)\n",
        "    done = terminated or truncated\n",
        "\n",
        "    # imprime as informações\n",
        "    print(\"action     :\", action)    \n",
        "    print(\"observation:\", state)\n",
        "    print(\"reward     :\", r)\n",
        "    print(\"-\")\n",
        "\n",
        "    # calcula a soma das recompensas\n",
        "    sum_rewards += r\n",
        "\n",
        "    # espera um pouco, para mostrar os resultados mais lentamente (se estiver rodando localmente)\n",
        "    #time.sleep(0.1)\n",
        "\n",
        "# encerra o ambiente, principalmente se usar renderização\n",
        "env.close()\n",
        "print(\"RETORNO DO EPISÓDIO (soma das recompensas):\", sum_rewards)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iA9fckVbsrBc"
      },
      "source": [
        "### 1.2 Gravando e Exibindo Vídeos\n",
        "\n",
        "Rodando no PC, você pode renderizar enquanto simula o ambiente. Se estiver rodando no Colab, a alternativa é salvar um vídeo e exibi-lo no final.\n",
        "\n",
        "A seguir, mostramos como **gravar vídeos** da execução do ambiente usando o wrapper `RecordVideo`. \n",
        "- Esta classe encapsula o ambiente original e pode ser usada como se fosse o próprio ambiente.\n",
        "- Internamente, ela executa o ambiente original e, adicionalmente, salva vídeos com a renderização dos passos. \n",
        "- Os vídeos são salvos em arquivos MP4 no diretório informado. Este exemplo salva apenas um vídeo, pois executa apenas um episódio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0c-0IH5f-se"
      },
      "outputs": [],
      "source": [
        "# diretório onde serão salvos os vídeos\n",
        "if IN_COLAB:\n",
        "    video_path = \"/content/videos\"\n",
        "else:\n",
        "    video_path = \"videos\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlSc5UU-sIod",
        "outputId": "17016207-d935-4209-b759-36b76508b10b"
      },
      "outputs": [],
      "source": [
        "# descomente apenas a linha do ambiente desejado\n",
        "env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "#env = gym.make(\"CartPole-v1\")\n",
        "#env = gym.make(\"Taxi-v3\")\n",
        "#env = gym.make(\"Pendulum-v1\")\n",
        "#env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "rec_env = gym.wrappers.RecordVideo(env, video_path, episode_trigger=lambda x : True)\n",
        "\n",
        "obs = rec_env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = rec_env.action_space.sample()\n",
        "    (obs, r, term, trunc, _) = rec_env.step(action)\n",
        "    done = term or trunc\n",
        "\n",
        "rec_env.close()\n",
        "clear_output()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N8mQ34Iv1tVg"
      },
      "source": [
        "Para exibir os vídeos em um notebook Jupyter/Python, usamos a função `display_videos_from_path()` passando o caminho do diretório dos vídeos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "oIRnRTza1vNe",
        "outputId": "4b289d48-f059-433b-b22d-a42b0ac956b9"
      },
      "outputs": [],
      "source": [
        "display_videos_from_path(video_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A5YgHc745SKc"
      },
      "source": [
        "## 2 - Solução Manual"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-ga0cRcwdC4f"
      },
      "source": [
        "Vamos tentar resolver o ambiente **Mountain Car** criando um algoritmo \"manual\" para escolher a ação.\n",
        "\n",
        "Este algoritmo é o que chamamos de **política** do agente. \n",
        "\n",
        "Para criar a política, vamos precisar entender bem o ambiente. Vejas informações detalhadas aqui: https://www.gymlibrary.dev/environments/classic_control/mountain_car/ . \n",
        "\n",
        "Segue um resumo:\n",
        "\n",
        "- O episódio **termina**:\n",
        "  - quando o carro chega na *bandeira* no lado direito\n",
        "  - ou quando atingir o máximo de 200 passos sem chegar lá\n",
        "- Cada **observação** deste ambiente é uma lista com estas duas informações:\n",
        "  - *índice 0* - posição no carro no eixo *x*\n",
        "  - *índice 1* - velocidade do carro \n",
        "- As **ações** possíveis são:\n",
        "  - *0* - acelerar para a esquerda\n",
        "  - *1* - deixar livre\n",
        "  - *2* - acelerar para a direita\n",
        "- A cada passo, a **recompensa** é -1, para incentivar o agente a encerrar a tarefa rapidamente\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z_OK4bVi3Dz"
      },
      "source": [
        "***Agora, tente criar sua solução (sua política)!*** \n",
        "\n",
        "Você saberá que resolveu o ambiente se o retorno do episódio for acima de -200 (por exemplo: -157)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VVRaDTH5T67",
        "outputId": "2e3a1582-1f9d-44ff-acd6-60347bfe2028"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
        "env = gym.wrappers.RecordVideo(env, video_path)\n",
        "\n",
        "state, _ = env.reset()\n",
        "done = False\n",
        "sum_rewards = 0.0\n",
        "\n",
        "while not done:\n",
        "    #env.render()   # precisa iniciar o ambiente com: render_mode=\"human\"\n",
        "    \n",
        "    posx = state[0]\n",
        "    vel = state[1]\n",
        "\n",
        "    # uma política determinística criada manualmente\n",
        "    if posx > -0.6 and vel > 0:\n",
        "        action = 2  # mover para a direita\n",
        "    else:\n",
        "        action = 1  # deixar livre\n",
        "\n",
        "    state, reward, termi, trunc, _ = env.step(action)\n",
        "    done = trunc or termi\n",
        "    sum_rewards += reward\n",
        "\n",
        "env.close()\n",
        "clear_output()\n",
        "print(\"Retorno:\", sum_rewards)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "6ZIBTMdUWKpW",
        "outputId": "d1aa1505-e227-4b7f-cd29-9067eaa1f8a8"
      },
      "outputs": [],
      "source": [
        "display_videos_from_path(video_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IoS1sK38deLH"
      },
      "source": [
        "Você consegue fazer uma solução melhor sem precisar deixar o carrinho livre (sem usar `action=1`).\n",
        "\n",
        "Para chegar a uma boa solução, pense no seguinte:\n",
        "- em quais situações faz sentido acelerar para a esquerda (`action=0`)?\n",
        "- em quais situações faz sentido acelerar para a direita (`action=2`)?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B_F2AShc4K_K"
      },
      "source": [
        "## 3 - Informações Sobre o Ambiente"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "swPxD3Cth1PM"
      },
      "source": [
        "Os ambientes podem ter observações contínuas (geralmente como listas de valores float) ou discretas (geralmente um único inteiro).\n",
        "\n",
        "Também as ações podem ser contínuas ou discretas. Cada ambiente do `gym` informa:\n",
        "- qual o seu **espaço de observações** (atributo `env.observation_space`)\n",
        "- e o seu **espaço de ações** (atributo `env.action_space`)\n",
        "\n",
        "Criamos a função abaixo para ler um espaço (de ações ou observações) e detalhar suas informações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLbDE6KHhzcE"
      },
      "outputs": [],
      "source": [
        "def print_space_info(space):\n",
        "    if isinstance(space, gym.spaces.Discrete):\n",
        "        print(\"   - quantidade de valores:\", space.n)\n",
        "    elif isinstance(space, gym.spaces.Box):\n",
        "        print(\"   - formato/shape:\", space.shape)\n",
        "        print(\"   - valores mínimos (por item):\", space.low)\n",
        "        print(\"   - valores máximos (por item):\", space.high)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9NYqAmPztCH",
        "outputId": "c50cb3b1-0b7f-40cd-bf37-8a660cc3cafd"
      },
      "outputs": [],
      "source": [
        "#env = gym.make(\"MountainCar-v0\")\n",
        "#env = gym.make(\"Taxi-v3\")\n",
        "#env = gym.make(\"CartPole-v1\")\n",
        "env = gym.make(\"Pendulum-v1\")\n",
        "#env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "print(\"INFORMAÇÕES SOBRE O AMBIENTE\", env)\n",
        "print()\n",
        "print(\"=> OBSERVATION SPACE:\", env.observation_space)\n",
        "print_space_info(env.observation_space)\n",
        "\n",
        "print()\n",
        "print(\"=> ACTION SPACE:\", env.action_space)\n",
        "print_space_info(env.action_space)\n",
        "print()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "smg02K4E2QKN"
      },
      "source": [
        "## 4 - Definindo Wrappers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDUfFU0q0nkH",
        "outputId": "0bbb6f1e-96c4-4919-cd7b-800b5fa588c9"
      },
      "outputs": [],
      "source": [
        "class PunishEarlyStop(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "    \n",
        "    def step(self, action):\n",
        "        obs, reward, termi, trunc, info = self.env.step(action)\n",
        "        # if ended because the pole fell down\n",
        "        if termi:\n",
        "            reward = -100\n",
        "        return obs, reward, termi, trunc, info\n",
        "\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "env = PunishEarlyStop(env)\n",
        "\n",
        "obs = env.reset()\n",
        "done = False\n",
        "sum_rewards = 0.0\n",
        "\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    sum_rewards += reward\n",
        "\n",
        "env.close()\n",
        "print(\"Recompensa total:\", sum_rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNPO8FtjsEtxWzIKLe3DMIu",
      "collapsed_sections": [
        "659YAN1F2VMu",
        "-7RVzsGP4UEE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
