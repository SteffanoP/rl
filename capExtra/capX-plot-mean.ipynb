{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Cap X - Gráficos de Média e Desvio Padrão com Stable-baselines\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pablo-sampaio/rl_facil/blob/main/capExtra/capX-plot-mean.ipynb)\n",
        "\n",
        "Vamos comparar os algoritmos **A2C** e **DQN** em várias execuções neste Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWskDE2c9WoN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert 'google.colab' in sys.modules, 'Notebook criado para o Colab'\n",
        "\n",
        "from IPython.display import clear_output\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install \"stable-baselines3[extra]==2.0.0\"\n",
        "\n",
        "# clone repository\n",
        "!git clone https://github.com/pablo-sampaio/rl_facil\n",
        "sys.path.append(\"/content/rl_facil\")\n",
        "\n",
        "#clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwO0bAqmAPw0"
      },
      "outputs": [],
      "source": [
        "!mkdir log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import tensorboard\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import stable_baselines3\n",
        "stable_baselines3.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgAXxClR0BfH"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import A2C, DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A00W6yY3NkHG"
      },
      "source": [
        "## 1 - Visualização no Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MkjYOgx3itp"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## 2 - Executar Vários Treinamentos com cada Algoritmo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFlacCbNv4zy"
      },
      "outputs": [],
      "source": [
        "NUM_RUNS = 3\n",
        "TOTAL_TRAINING_STEPS = 40_000\n",
        "ENVIRONMENT_ID = \"CartPole-v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26LTUX1XxKDT"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUWGZp3i9wyf"
      },
      "outputs": [],
      "source": [
        "for x in tqdm(range(NUM_RUNS)):\n",
        "    model3 = A2C('MlpPolicy', ENVIRONMENT_ID, n_steps=16, ent_coef=0.01, verbose=0, tensorboard_log=\"log_dir\").learn(TOTAL_TRAINING_STEPS+1_000)\n",
        "    # o valor de +1_000 é para garantir que o log tem dados suficientes para a visualização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozKLv1uZv4z6"
      },
      "outputs": [],
      "source": [
        "for x in tqdm(range(NUM_RUNS)):\n",
        "    model2 = DQN('MlpPolicy', ENVIRONMENT_ID, buffer_size=10_000, learning_starts=2_000, target_update_interval=2_500, tensorboard_log=\"log_dir\", verbose=0).learn(TOTAL_TRAINING_STEPS+1_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LSG9SuXrjQR"
      },
      "source": [
        "## 3 - Mostrar Gráficos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### 3.1 Definições necessárias\n",
        "\n",
        "Funções auxiliares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "\n",
        "def load_data_from_logs(log_dir, data_tag):\n",
        "    event_acc = event_accumulator.EventAccumulator(log_dir)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    # Get a list of all available tags (usually scalars)\n",
        "    tags = event_acc.Tags()['scalars']\n",
        "\n",
        "    data = []\n",
        "    for event in event_acc.Scalars(data_tag):\n",
        "        data.append((event.step, event.value))\n",
        "\n",
        "    return data\n",
        "\n",
        "def process_grandchild_folders(root_dir, subfolder_prefix, data_tag):\n",
        "    collected_data = []\n",
        "    for parent_dir, _, grandchild_dirs in os.walk(root_dir):\n",
        "        parent_folder = os.path.basename(parent_dir)\n",
        "        if parent_folder.startswith(subfolder_prefix):\n",
        "            for grandchild_dir in grandchild_dirs:\n",
        "                log_dir = os.path.join(parent_dir, grandchild_dir)\n",
        "                print(f\"Loading data from {log_dir}\")\n",
        "                data = load_data_from_logs(log_dir, data_tag)\n",
        "                collected_data.append(data)\n",
        "    return collected_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwUCJU8vv40B"
      },
      "outputs": [],
      "source": [
        "# Just a test\n",
        "#root_folder = 'log_dir/'\n",
        "#all_data = process_grandchild_folders(root_folder, 'DQN', 'rollout/ep_len_mean')\n",
        "#all_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from util.experiments import process_returns_linear_interpolation\n",
        "\n",
        "def plot_mean_std_curve(alg_prefix):\n",
        "  # Assuming you have loaded the data for a specific tag as a list of lists\n",
        "  # all_data = [\n",
        "  #     [(timestep1, value1), (timestep2, value2), ...],\n",
        "  #     [(timestep1, value1), (timestep2, value2), ...],\n",
        "  # ]\n",
        "\n",
        "  root_folder = 'log_dir/'\n",
        "  all_data = process_grandchild_folders(root_folder, alg_prefix, 'rollout/ep_len_mean')\n",
        "\n",
        "  # Create a dictionary to organize data by timestep\n",
        "  # TODO: considerar tratar todos como dados heterogêneos\n",
        "  homogeneous = True\n",
        "  timestep_data = {}\n",
        "\n",
        "  for i, run_values in enumerate(all_data):\n",
        "      for timestep, value in run_values:\n",
        "          if timestep not in timestep_data:\n",
        "              timestep_data[timestep] = []\n",
        "              if i >= 1:\n",
        "                  homogeneous = False\n",
        "                  break\n",
        "          timestep_data[timestep].append(value)\n",
        "\n",
        "  # Calculate mean and standard deviation for each timestep\n",
        "  if homogeneous:\n",
        "      mean_values = []\n",
        "      std_dev_values = []\n",
        "\n",
        "      for timestep, values_at_timestep in timestep_data.items():\n",
        "          mean_values.append(np.mean(values_at_timestep))\n",
        "          std_dev_values.append(np.std(values_at_timestep))\n",
        "\n",
        "      timesteps = sorted(timestep_data.keys())\n",
        "\n",
        "  else:\n",
        "      print(\"Heter\")\n",
        "      runs = len(all_data)\n",
        "      timestep_data = np.zeros((runs, TOTAL_TRAINING_STEPS), np.float32)\n",
        "      for i in range(runs):\n",
        "          timestep_data[i] = process_returns_linear_interpolation(all_data[i], TOTAL_TRAINING_STEPS)\n",
        "\n",
        "      mean_values, std_dev_values = timestep_data.mean(axis=0), timestep_data.std(axis=0)\n",
        "      timesteps = range(1,TOTAL_TRAINING_STEPS+1)\n",
        "\n",
        "  # Create the plot\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(timesteps, mean_values, label='Mean')\n",
        "  plt.fill_between(timesteps, np.subtract(mean_values, std_dev_values), np.add(mean_values, std_dev_values), alpha=0.2, label='Std. Dev.')\n",
        "\n",
        "  plt.xlabel('Timestep')\n",
        "  plt.ylabel('Value')\n",
        "  plt.title('Mean and Standard Deviation Plot')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOObbeu5MMlR"
      },
      "source": [
        "### 3.2 Desenha os Gráficos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iATu7AiyMQW2"
      },
      "outputs": [],
      "source": [
        "plot_mean_std_curve('A2C')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n4i-fW3NojZ"
      },
      "outputs": [],
      "source": [
        "plot_mean_std_curve('DQN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVXnKIJLDPuj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FtY8FhliLsGm",
        "xVm9QPNVwKXN"
      ],
      "name": "capX-plot-mean.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('rlx')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.17"
    },
    "vscode": {
      "interpreter": {
        "hash": "27dbc9ce4cc602e4f15257b7b0018d8dff5b9ce9a7d73bc4399cb5afb1e02c4a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
