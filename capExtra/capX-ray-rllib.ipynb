{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkcSb01nbfZCffeggk2mp8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablo-sampaio/rl_facil/blob/main/capExtra/capX-ray-rllib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sp2sD2qEpdyv"
      },
      "outputs": [],
      "source": [
        "!pip install \"ray[rllib]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import tensorboard\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "from ray.rllib.algorithms.ppo import PPOConfig\n",
        "from ray.tune.logger import pretty_print"
      ],
      "metadata": {
        "id": "O-lNOa_Kre4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Tensorboard"
      ],
      "metadata": {
        "id": "0NdPDuelsfr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acompanhe, em especial, a métrica `ray/tune/episode_reward_mean` ou `ray/tune/sampler_results\n",
        "/episode_reward_mean`."
      ],
      "metadata": {
        "id": "DMMtj_AQsjE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=~/ray_results  # no Colab, os resultados ficam em \"root/ray_results\""
      ],
      "metadata": {
        "id": "nmCY7US9sbIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Treinamento com o PPO"
      ],
      "metadata": {
        "id": "UPgs8IIIrmpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ENV_NAME = 'MountainCarContinuous-v0' #'CartPole-v1'"
      ],
      "metadata": {
        "id": "182zXNv_359n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo = (\n",
        "    PPOConfig()\n",
        "    .rollouts(num_rollout_workers=0)\n",
        "    .resources(num_gpus=1)           # atenção: 1 GPU\n",
        "    .environment(env=ENV_NAME)\n",
        "    .build()\n",
        ")\n",
        "\n",
        "# treina 4 mil passos por iteração\n",
        "for i in range(20):\n",
        "    result = algo.train()\n",
        "    clear_output()\n",
        "\n",
        "    # result é um dicionário com muitas informações do treinamento\n",
        "    # se quiser tamanho e recompensa de cada episódio, acesse result['sampler_results']['hist_stats'].keys()\n",
        "    print(pretty_print(result))\n",
        "\n",
        "    if (i+1) % 5 == 0:\n",
        "        checkpoint_dir = algo.save()\n",
        "        print(f\"Checkpoint saved in directory {checkpoint_dir}\")"
      ],
      "metadata": {
        "id": "0K1oKdrZpeer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Execução do Agente Treinado"
      ],
      "metadata": {
        "id": "9nzKOitQrpxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make(ENV_NAME)\n",
        "\n",
        "for i in range(5):\n",
        "  episode_reward = 0\n",
        "  terminated = truncated = False\n",
        "  obs, info = env.reset()\n",
        "\n",
        "  while not terminated and not truncated:\n",
        "      action = algo.compute_single_action(obs)\n",
        "      obs, reward, terminated, truncated, info = env.step(action)\n",
        "      episode_reward += reward\n",
        "\n",
        "  print(f'Episode {i+1} -> {episode_reward=}')\n"
      ],
      "metadata": {
        "id": "ykaGs87tqJU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TAx3QbIqDfwo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}